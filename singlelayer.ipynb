{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Softmax, LeakyReLU, BatchNormalization, AveragePooling2D, Reshape, Flatten \n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_name):\n",
    "    \"\"\"Check if dir_name/ exits and create directory if not exits\n",
    "    Args:\n",
    "        dir_name (str): Name of dir to be created\n",
    "    Returns:\n",
    "        None: [description]\n",
    "    \"\"\"\n",
    "    Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    \"\"\"Create timestamp sting\n",
    "    Returns:\n",
    "        str: Timestamp\n",
    "    \"\"\"\n",
    "    time_info = datetime.today()\n",
    "    timestamp = f\"{time_info.year}-{time_info.month}-{time_info.day}-{time_info.hour}-{time_info.minute}\"\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outputs_dir(tag=\"\"):\n",
    "    \"\"\"Creates output direcotry template\n",
    "    Args:\n",
    "        tag (str, optional): Optional tag appended to output dir. Defaults to \"\".\n",
    "    Returns:\n",
    "        str: Path to output folder\n",
    "    \"\"\"\n",
    "    # Get timestamp, append tag and create \"outputs/output_dir_name\"\n",
    "    output_dir_name = f\"outputs/{get_timestamp()}_{tag}\"\n",
    "    create_dir(output_dir_name)\n",
    "    # Create empty subfolders in <timestamp>/ for valid_predictions/, real_predictions/\n",
    "    create_dir(f\"{output_dir_name}/valid_predictions\")\n",
    "    create_dir(f\"{output_dir_name}/real_predictions\")\n",
    "    create_dir(f\"{output_dir_name}/logs\")\n",
    "    return output_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_annot(image, x_0, y_0, gamma, conf):\n",
    "    plt.figure(figsize=[6, 6])\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(x_0, y_0, color='r', s=40, marker=\"o\")\n",
    "\n",
    "    line_len = 20\n",
    "    for x_1, y_1, angle, confi in zip(x_0, y_0, gamma, conf):\n",
    "        x_2 = x_1 + line_len*math.cos(angle)\n",
    "        y_2 = y_1 + line_len*math.sin(angle)\n",
    "        plt.plot([x_1, x_2], [y_1, y_2], color='r')\n",
    "    plt.show\n",
    "    plt.savefig(\"predicted.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_annot(annot_path, check_params=[128]):\n",
    "\n",
    "    annot = np.loadtxt(annot_path)\n",
    "\n",
    "    # checking for number of data points\n",
    "    if annot.shape[1] != 7:\n",
    "        return False\n",
    "\n",
    "    # checking for x limits\n",
    "    if (annot[:, 1].max() > 128) or (annot[:, 1].min() < 0):\n",
    "        return False\n",
    "\n",
    "    # checking for y limits\n",
    "    if (annot[:, 2].max() > 128) or (annot[:, 2].min() < 0):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_sample(img_paths, ann_paths):\n",
    "    samples = []\n",
    "    # storing image_paths and corresponding annotation paths as a pair\n",
    "    for I_Path, A_Path in zip(img_paths, ann_paths):\n",
    "        if filter_annot(A_Path):\n",
    "            samples.append([I_Path, A_Path])\n",
    "    # shuffle the sample\n",
    "    random.shuffle(samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(img_paths, ann_paths, batch_size):\n",
    "    grid_h = 8\n",
    "    grid_w = 8\n",
    "    # get the shuffled samples\n",
    "    samples = shuffle_sample(img_paths, ann_paths)\n",
    "    num_samples = len(samples)\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            # x_train = np.zeros([batch_size, 128, 128, 1])\n",
    "            x_train = []\n",
    "            y_train = np.zeros([batch_size, 16, 16, 1, 5])\n",
    "            i = 0\n",
    "            for batch_sample in batch_samples:\n",
    "                img_name = batch_sample[0]\n",
    "                ann_name = batch_sample[1]\n",
    "                img = cv2.imread(str(img_name), 1)\n",
    "                img = cv2.resize(img, (128, 128))\n",
    "                img = img/255\n",
    "                # storing x_values back to back\n",
    "                # x_train[i, :, :, 0] = img\n",
    "                x_train.append(img)\n",
    "\n",
    "                annot = np.loadtxt(ann_name)\n",
    "                # finding which grid the object belongs to\n",
    "                grid_x = annot[:, 1]//grid_w\n",
    "                grid_y = annot[:, 2]//grid_h\n",
    "                row = 0\n",
    "                for cell_x, cell_y in zip(grid_x, grid_y):\n",
    "                    if ((annot[row, 5] + annot[row, 6])*0.5) > 0.6:\n",
    "                        y_train[i, int(cell_y), int(cell_x), 0, 0] = float(\n",
    "                            annot[row, 1]/8 % 1)\n",
    "                        y_train[i, int(cell_y), int(cell_x), 0,\n",
    "                                1] = float(annot[row, 1]/8 % 1)\n",
    "                        y_train[i, int(cell_y), int(cell_x), 0, 2] = float(\n",
    "                            (math.sin(annot[row, 3]))**2)  # I_xx\n",
    "                        y_train[i, int(cell_y), int(cell_x), 0, 3] = float(\n",
    "                            (math.sin(2*annot[row, 4])+1)*0.5)  # I_xy\n",
    "                        y_train[i, int(cell_y), int(cell_x),\n",
    "                                0, 4] = 1.0  # conf\n",
    "                        # y_train[i, int(cell_y), int(cell_x), 0, 5] = annot[row, 0]  # class\n",
    "                        row = row+1\n",
    "                i += 1\n",
    "\n",
    "            x_train = np.array(x_train)\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    DIRECTION_SCALE = 14.0\n",
    "    COORD_SCALE = 4.0\n",
    "    OBJECT_SCALE = 20.0\n",
    "    NO_OBJECT_SCALE = 8.0\n",
    "    # CLASS_SCALE = 1.0\n",
    "    mask_shape = tf.shape(y_true)[: 4]\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    direction_mask = tf.zeros(mask_shape)\n",
    "    conf_mask = tf.zeros(mask_shape)\n",
    "    # class_mask = tf.zeros(mask_shape)\n",
    "    pred_xy = (y_pred[..., 0: 2])\n",
    "    pred_exy = (y_pred[..., 2: 4])\n",
    "    pred_conf = y_pred[..., 4]\n",
    "    # pred_class = y_pred[..., 5:]\n",
    "    true_xy = y_true[..., 0: 2]\n",
    "    true_exy = y_true[..., 2: 4]\n",
    "    true_conf = y_true[..., 4]\n",
    "    # true_class = y_true[..., 5:]\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    direction_mask = tf.expand_dims(y_true[..., 4], axis=-1) * DIRECTION_SCALE\n",
    "    conf_mask = conf_mask + (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    # class_mask = tf.expand_dims(y_true[..., 4], axis=-1) * CLASS_SCALE\n",
    "    nb_coord_kpp = tf.reduce_sum(tf.cast(coord_mask > 0.0, dtype=tf.float32))\n",
    "    nb_conf_kpp = tf.reduce_sum(tf.cast(conf_mask > 0.0, dtype=tf.float32))\n",
    "    # nb_class_kpp = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\n",
    "    loss_xy = tf.reduce_sum(tf.square(true_xy-pred_xy)\n",
    "                            * coord_mask) / (nb_coord_kpp + 1e-6) / 2.\n",
    "    loss_exy = tf.reduce_sum(tf.square(true_exy-pred_exy)\n",
    "                             * direction_mask) / (nb_coord_kpp + 1e-6) / 2.\n",
    "    loss_conf = tf.reduce_sum(\n",
    "        tf.square(true_conf-pred_conf) * conf_mask) / (nb_conf_kpp + 1e-6) / 2.\n",
    "    # loss_class = tf.reduce_sum(tf.square(true_class-pred_class) * class_mask) / (nb_class_kpp + 1e-6) / 2.\n",
    "    # loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_class, logits=pred_class)\n",
    "    # loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_coord_box + 1e-6)\n",
    "    loss = loss_xy + loss_exy + loss_conf  # + loss_class\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.8\n",
    "    decay_step = 20\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_annot(output):\n",
    "    grid_w = 8\n",
    "    grid_h = 8\n",
    "    x_0 = []\n",
    "    y_0 = []\n",
    "    gamma = []\n",
    "    conf = []\n",
    "    # classes= []\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if output[i, j, 4] > 0.1:\n",
    "                X = output[i, j, 0]*grid_w + grid_w*j\n",
    "                x_0.append(X)\n",
    "                Y = output[i, j, 1]*grid_h + grid_h*i\n",
    "                y_0.append(Y)\n",
    "                # angle = 0.5*math.asin((2*output[i, j, 3] - 1))\n",
    "                angle = float(math.atan2(\n",
    "                    output[i, j, 2] * 2, output[i, j, 3] * 2 - 1))\n",
    "                gamma.append(angle)\n",
    "                conf.append(output[i, j, 4])\n",
    "                # classes.append(output[i,j,5])\n",
    "    return x_0, y_0, gamma, conf  # , classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(img_file_list, model, output_path, limit=10):\n",
    "    \"\"\"Predict and save images based on model\n",
    "    Args:\n",
    "        img_file_list (list): Image file paths\n",
    "        model (tensorflow.model): Trained model\n",
    "        output_path (str): Path to save images\n",
    "        limit (int, optional): Maximum number of images to be predicted. Defaults to 10.\n",
    "    \"\"\"\n",
    "    # Limiting the prediction dataset\n",
    "    img_file_list = img_file_list[:limit]\n",
    "    for img_f in img_file_list:\n",
    "        img = cv2.imread(str(img_f), 0)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img_ = img / 255\n",
    "        img_ = np.expand_dims(img_, axis=-1)\n",
    "        img_ = np.expand_dims(img_, axis=0)\n",
    "        out = model.predict(img_)\n",
    "        reshaped = out.reshape((16, 16, 5))\n",
    "        x, y, gamma, conf = decode_annot(reshaped)\n",
    "        max_conf = np.max(reshaped[:, :, 4])\n",
    "        print('max confidence = ', max_conf)\n",
    "        draw_annot(img, x, y, gamma, conf, f\"{output_path}/{img_f.stem}.png\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train samples:  1401\n",
      "num of valid samples:  599\n"
     ]
    }
   ],
   "source": [
    "# Create output folder\n",
    "OUTPUT_DIR_PATH = create_outputs_dir()\n",
    "\n",
    "# Training params\n",
    "EPOCHS =3\n",
    "BS = 2\n",
    "    \n",
    "\n",
    "\n",
    "TRAIN_DATASET_PATH = Path(\"datasets/128_singlelayer/train\")\n",
    "VALID_DATASET_PATH = Path(\"datasets/128_singlelayer/valid\")\n",
    "\n",
    "# train_img_paths = list(TRAIN_DATASET_PATH.glob(\"**/*.bmp\"))\n",
    "\n",
    "# for item in train_img_paths:\n",
    "#     image = cv2.imread(str(item), 0)\n",
    "#     image = np.dstack((image, image, image))\n",
    "#     write_path = str(item)\n",
    "#     write_path = write_path.replace(\"train\", \"train_s_3\")\n",
    "#     cv2.imwrite(write_path, image)\n",
    "\n",
    "# valid_img_paths = list(VALID_DATASET_PATH.glob(\"**/*.bmp\"))\n",
    "\n",
    "# for item in valid_img_paths:\n",
    "#     image = cv2.imread(str(item), 0)\n",
    "#     image = np.dstack((image, image, image))\n",
    "#     write_path = str(item)\n",
    "#     write_path = write_path.replace(\"valid\", \"valid_s_3\")\n",
    "#     cv2.imwrite(write_path, image)\n",
    "\n",
    "TRAIN_IMG_DATASET_PATH = Path(\"datasets/128_singlelayer/train_s_3\")\n",
    "VALID_IMG_DATASET_PATH = Path(\"datasets/128_singlelayer/valid_s_3\")\n",
    "\n",
    "train_img_paths = list(TRAIN_IMG_DATASET_PATH.glob(\"**/*.bmp\"))\n",
    "train_ann_paths = list(TRAIN_DATASET_PATH.glob(\"**/*.txt\"))\n",
    "\n",
    "valid_img_paths = list(VALID_IMG_DATASET_PATH.glob(\"**/*.bmp\"))\n",
    "valid_ann_paths = list(VALID_DATASET_PATH.glob(\"**/*.txt\"))\n",
    "\n",
    "num_train_samples = len(train_ann_paths)\n",
    "num_valid_samples = len(valid_img_paths)\n",
    "\n",
    "print('num of train samples: ', num_train_samples)\n",
    "print('num of valid samples: ', num_valid_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = data_generator(train_img_paths, train_ann_paths, 2)\n",
    "validation_datagen = data_generator(valid_img_paths, valid_ann_paths, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              67110912  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 5)         1445      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 5)         20        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 16, 16, 5)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 1, 5)      0         \n",
      "=================================================================\n",
      "Total params: 90,720,393\n",
      "Trainable params: 67,132,383\n",
      "Non-trainable params: 23,588,010\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = ResNet50(input_shape = (128, 128, 3), \n",
    "                                include_top = False, \n",
    "                                weights =\"imagenet\")\n",
    "\n",
    "# for layer in pre_trained_model.layers[:143]:\n",
    "#         layer.trainable = False \n",
    "\n",
    "pre_trained_model.trainable = False\n",
    "#pre_trained_model.summary()\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(pre_trained_model)\n",
    "add_model.add(Flatten())\n",
    "add_model.add(Dropout(0.4))\n",
    "add_model.add(Dense(2048, activation='relu'))\n",
    "add_model.add(Reshape((32, 32, 2)))\n",
    "add_model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "add_model.add(BatchNormalization())\n",
    "add_model.add(LeakyReLU(alpha=0.1))\n",
    "add_model.add(AveragePooling2D(2, 2))\n",
    "\n",
    "for i in range(0, 3):\n",
    "    add_model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "    add_model.add(BatchNormalization())\n",
    "    add_model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "add_model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "add_model.add(BatchNormalization())\n",
    "add_model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "add_model.add(Conv2D(5, (3, 3), padding='same'))\n",
    "add_model.add(BatchNormalization())\n",
    "add_model.add(Softmax())\n",
    "\n",
    "add_model.add(Reshape((16, 16, 1, 5)))\n",
    "\n",
    "add_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model.compile(optimizer = Adam(lr=0.005),\n",
    "                    loss = custom_loss,\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "Epoch 1/3\n",
      "1066/1401 [=====================>........] - ETA: 20:22 - loss: 2.0127 - accuracy: 0.1142"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-465e3227f58e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m history = add_model.fit(x = train_datagen,\n\u001b[0m\u001b[0;32m     24\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_datagen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_train_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=0.001,\n",
    "                                   patience=300,  # 2or3\n",
    "                                   mode='min',\n",
    "                                   verbose=1)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(f\"{OUTPUT_DIR_PATH}/trained_SL_best.h5\",\n",
    "#                                  monitor='val_loss',\n",
    "#                                  verbose=1,\n",
    "#                                  save_best_only=True,\n",
    "#                                  save_weights_only=False,\n",
    "#                                  mode='min',\n",
    "#                                  period=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"{OUTPUT_DIR_PATH}/logs\",\n",
    "                              histogram_freq=0,\n",
    "                              # write_batch_performance=True,\n",
    "                              write_graph=True,\n",
    "                              write_images=False)\n",
    "\n",
    "l_rate= LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "\n",
    "history = add_model.fit(x = train_datagen,\n",
    "                        validation_data = validation_datagen,\n",
    "                        steps_per_epoch = num_train_samples,\n",
    "                        validation_steps = num_valid_samples,\n",
    "                        epochs = 3,\n",
    "                        callbacks = [early_stop, l_rate,\n",
    "                                   tensorboard],\n",
    "                        verbose = 1)\n",
    "\n",
    "# Saving the trained model\n",
    "add_model.save(f\"{OUTPUT_DIR_PATH}/trained_SL_last.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating Accuracy and Loss\n",
    "# -----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "# -----------------------------------------------------------\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))  # Get number of epochs\n",
    "# ------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "# ------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, label='training')\n",
    "plt.plot(epochs, val_acc, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.savefig(f\"{OUTPUT_DIR_PATH}/training-accuracy-plot.png\")\n",
    "# ------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "# ------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='training')\n",
    "plt.plot(epochs, val_loss, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and validation loss')\n",
    "plt.savefig(f\"{OUTPUT_DIR_PATH}/training-loss-plot.png\")\n",
    "# ------------------------------------------------\n",
    "# Load best weights\n",
    "# ------------------------------------------------\n",
    "# ------------------------------------------------\n",
    "# PREDICTION\n",
    "# ------------------------------------------------\n",
    "save_predictions(valid_img_paths, model,\n",
    "                     output_path=f\"{OUTPUT_DIR_PATH}/valid_predictions\")\n",
    "save_predictions(real_img_paths, model,\n",
    "                     output_path=f\"{OUTPUT_DIR_PATH}/real_predictions\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec0e007005ff76f92e7f79ed5f98b599fbe035c2eb365d9361a140832d17fa63"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('tf-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
