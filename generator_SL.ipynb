{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math\r\n",
    "from pathlib import Path\r\n",
    "import numpy as np \r\n",
    "import cv2\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import cm\r\n",
    "import random\r\n",
    "\r\n",
    "from tensorflow.keras.layers import Conv2D, Softmax, Activation,BatchNormalization, AveragePooling2D, Reshape, Dropout, LeakyReLU, Dense\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\r\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy, SparseCategoricalCrossentropy, MeanSquaredError\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRAIN_DATASET_PATH = Path(\"datasets/128_singlelayer/train\")\r\n",
    "VALID_DATASET_PATH = Path(\"datasets/128_singlelayer/valid\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_img_paths = list(TRAIN_DATASET_PATH.glob(\"**/*.bmp\"))\r\n",
    "train_ann_paths = list(TRAIN_DATASET_PATH.glob(\"**/*.txt\"))\r\n",
    "\r\n",
    "valid_img_paths = list(VALID_DATASET_PATH.glob(\"**/*.bmp\"))\r\n",
    "valid_ann_paths = list(VALID_DATASET_PATH.glob(\"**/*.txt\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " num_train_samples = len(train_ann_paths)\r\n",
    " num_valid_samples = len(valid_img_paths)\r\n",
    "\r\n",
    "print('num of train samples: ', num_train_samples)\r\n",
    "print('num of valid samples: ', num_valid_samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Viewer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def draw_annot(image, x_0 , y_0 , gamma , conf ):\r\n",
    "    plt.figure(figsize = [6,6])\r\n",
    "    plt.imshow(image)\r\n",
    "    plt.scatter(x_0, y_0, color='r', s=40, marker= \"o\")\r\n",
    "    \r\n",
    "    line_len = 20\r\n",
    "    for x_1,y_1,angle,confi in zip (x_0,y_0,gamma,conf):\r\n",
    "        x_2 = x_1 + line_len*math.cos(angle)\r\n",
    "        y_2 = y_1 + line_len*math.sin(angle)\r\n",
    "        plt.plot([x_1,x_2],[y_1,y_2] , color='r')   \r\n",
    "    plt.show"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num = 30\r\n",
    "Image = cv2.imread(str(train_img_paths[num]))\r\n",
    "Annot = np.loadtxt(train_ann_paths[num])\r\n",
    "X = Annot[:,1]\r\n",
    "Y = Annot[:,2]\r\n",
    "Gamma = Annot[:,3]\r\n",
    "Conf = (Annot[:,5] + Annot[:,6])*0.5\r\n",
    "Classes = Annot[:,0]\r\n",
    "\r\n",
    "draw_annot(Image, X, Y, Gamma, Conf)\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering Annotation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def filter_annot(annot_path, check_params=[128]):\r\n",
    "\r\n",
    "    annot = np.loadtxt(annot_path)\r\n",
    "\r\n",
    "    # checking for number of data points\r\n",
    "    if annot.shape[1] != 7:\r\n",
    "        return False\r\n",
    "\r\n",
    "    # checking for x limits\r\n",
    "    if (annot[:, 1].max() > 128) or (annot[:, 1].min() < 0):\r\n",
    "        return False\r\n",
    "\r\n",
    "    # checking for y limits\r\n",
    "    if (annot[:, 2].max() > 128) or (annot[:, 2].min() < 0):\r\n",
    "        return False\r\n",
    "\r\n",
    "    return True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shuffling Sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def shuffle_sample(img_paths, ann_paths):\r\n",
    "    samples = []\r\n",
    "    #storing image_paths and corresponding annotation paths as a pair\r\n",
    "    for I_Path,A_Path in zip(img_paths,ann_paths):\r\n",
    "        if filter_annot(A_Path):\r\n",
    "            samples.append([I_Path, A_Path])\r\n",
    "    #shuffle the sample\r\n",
    "    random.shuffle(samples)\r\n",
    "    return samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Data Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def data_generator(img_paths, ann_paths, batch_size):\r\n",
    "    grid_h = 8\r\n",
    "    grid_w = 8\r\n",
    "    \r\n",
    "    #get the shuffled samples\r\n",
    "    samples = shuffle_sample(img_paths , ann_paths)\r\n",
    "    num_samples = len(samples)\r\n",
    "    while True: # Loop forever so the generator never terminates\r\n",
    "    \r\n",
    "        for offset in range(0, num_samples, batch_size):\r\n",
    "            # Get the samples you'll use in this batch\r\n",
    "            batch_samples = samples[offset:offset+batch_size]\r\n",
    "\r\n",
    "            # Initialise X_train and y_train arrays for this batch\r\n",
    "            x_train = np.zeros([batch_size, 128, 128, 1])\r\n",
    "            y_train = np.zeros([batch_size, 16, 16, 1, 5])\r\n",
    "\r\n",
    "            i=0\r\n",
    "            for batch_sample in batch_samples:\r\n",
    "                img_name = batch_sample[0]\r\n",
    "                ann_name = batch_sample[1]\r\n",
    "                \r\n",
    "                img = cv2.imread(str(img_name),0)\r\n",
    "                img = cv2.resize(img,(128,128))\r\n",
    "                img = img/255\r\n",
    "\r\n",
    "                #storing x_values back to back\r\n",
    "                x_train[i, :, :, 0] = img\r\n",
    "\r\n",
    "                annot = np.loadtxt(ann_name)\r\n",
    "                #finding which grid the object belongs to      \r\n",
    "                grid_x = annot[:,1]//grid_w\r\n",
    "                grid_y = annot[:,2]//grid_h\r\n",
    "\r\n",
    "                row = 0\r\n",
    "                \r\n",
    "                for cell_x, cell_y in zip(grid_x, grid_y):\r\n",
    "                    y_train[i,int(cell_y), int(cell_x), 0, 0] = (annot[row, 1] - grid_w * int(cell_x)) / grid_w # x_0\r\n",
    "                    y_train[i,int(cell_y), int(cell_x), 0, 1] = (annot[row, 2] - grid_h * int(cell_y)) / grid_h # y_0\r\n",
    "                    y_train[i,int(cell_y), int(cell_x), 0, 2] = (math.sin(annot[row, 3]))**2 # I_xx\r\n",
    "                    y_train[i,int(cell_y), int(cell_x), 0, 3] = (math.sin(2*annot[row, 4])+1)*0.5 # I_xy\r\n",
    "                    y_train[i,int(cell_y), int(cell_x), 0, 4] = 1 # conf\r\n",
    "                    #y_train[i,int(cell_y), int(cell_x), 0, 5] = annot[row, 0] # class\r\n",
    "                    row = row+1   \r\n",
    "                            \r\n",
    "                i+=1\r\n",
    "\r\n",
    "            yield x_train, y_train\r\n",
    "                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_datagen= data_generator(train_img_paths, train_ann_paths, 2)\r\n",
    "validation_datagen= data_generator(valid_img_paths, valid_ann_paths, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# x, y= next(validation_datagen)\r\n",
    "# print('x_shape:', x.shape)\r\n",
    "# print('y_shape:', y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def custom_loss(y_true, y_pred):\r\n",
    "\r\n",
    "    DIRECTION_SCALE = 5.0\r\n",
    "    COORD_SCALE = 1.0\r\n",
    "    OBJECT_SCALE = 10.0\r\n",
    "    NO_OBJECT_SCALE = 5\r\n",
    "    #CLASS_SCALE = 1.0\r\n",
    "    \r\n",
    "    mask_shape = tf.shape(y_true)[:4]\r\n",
    "\r\n",
    "    coord_mask = tf.zeros(mask_shape)\r\n",
    "    direction_mask = tf.zeros(mask_shape)\r\n",
    "    conf_mask  = tf.zeros(mask_shape)\r\n",
    "    #class_mask = tf.zeros(mask_shape)\r\n",
    "\r\n",
    "\r\n",
    "    pred_xy = (y_pred[..., 0:2]) \r\n",
    "    pred_exy = (y_pred[..., 2:4])\r\n",
    "    pred_conf = y_pred[..., 4]\r\n",
    "    #pred_class = y_pred[..., 5:]\r\n",
    "\r\n",
    "    true_xy = y_true[..., 0:2]    \r\n",
    "    true_exy = y_true[..., 2:4]\r\n",
    "    true_conf = y_true[..., 4]\r\n",
    "    #true_class = y_true[..., 5:]\r\n",
    "\r\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\r\n",
    "    direction_mask = tf.expand_dims(y_true[..., 4], axis=-1) * DIRECTION_SCALE\r\n",
    "    conf_mask = conf_mask + (1 - y_true[..., 4]) * NO_OBJECT_SCALE\r\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\r\n",
    "    #class_mask = tf.expand_dims(y_true[..., 4], axis=-1) * CLASS_SCALE\r\n",
    "\r\n",
    "\r\n",
    "    nb_coord_kpp = tf.reduce_sum(tf.cast(coord_mask > 0.0, dtype=tf.float32))\r\n",
    "    nb_conf_kpp = tf.reduce_sum(tf.cast(conf_mask > 0.0, dtype=tf.float32))\r\n",
    "    #nb_class_kpp = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\r\n",
    "\r\n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_xy-pred_xy) * coord_mask) / (nb_coord_kpp + 1e-6) / 2.\r\n",
    "    loss_exy    = tf.reduce_sum(tf.square(true_exy-pred_exy) * direction_mask) / (nb_coord_kpp + 1e-6) / 2.\r\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_conf-pred_conf) * conf_mask)  / (nb_conf_kpp  + 1e-6) / 2.\r\n",
    "    #loss_class = tf.reduce_sum(tf.square(true_class-pred_class) * class_mask)  / (nb_class_kpp  + 1e-6) / 2.  \r\n",
    "\r\n",
    "    # loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_class, logits=pred_class)\r\n",
    "    # loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_coord_box + 1e-6)\r\n",
    "\r\n",
    "    loss = loss_xy + loss_exy + loss_conf #+ loss_class\r\n",
    "    \r\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential([\r\n",
    "    Conv2D(16, (3,3),padding='same', input_shape=(128, 128, 1)),\r\n",
    "    BatchNormalization(),\r\n",
    "    Activation('relu'),\r\n",
    "    AveragePooling2D(2,2),\r\n",
    "    Conv2D(32, (3,3), padding='same'),\r\n",
    "    BatchNormalization(),\r\n",
    "    Activation('relu'),\r\n",
    "    AveragePooling2D(2,2), \r\n",
    "    Conv2D(5, (3,3),padding='same'),\r\n",
    "    BatchNormalization(),\r\n",
    "    Activation('relu'), \r\n",
    "    AveragePooling2D(2,2),\r\n",
    "    Reshape((16,16,1,5))\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model = tf.keras.Sequential()\r\n",
    "# model.add(Conv2D(64, (3, 3), padding='same', input_shape=(128, 128, 1)))\r\n",
    "# model.add(BatchNormalization())\r\n",
    "# model.add(LeakyReLU(alpha=0.1))\r\n",
    "\r\n",
    "# for i in range(0, 20):\r\n",
    "#     model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "#     model.add(BatchNormalization())\r\n",
    "#     model.add(LeakyReLU(alpha=0.1))\r\n",
    "    \r\n",
    "# model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "# model.add(BatchNormalization())\r\n",
    "# model.add(LeakyReLU(alpha=0.1))\r\n",
    "# model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "# for i in range(0, 15):\r\n",
    "#     model.add(Conv2D(16, (3, 3), padding='same'))\r\n",
    "#     model.add(BatchNormalization())\r\n",
    "#     model.add(LeakyReLU(alpha=0.1))\r\n",
    "    \r\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
    "# model.add(BatchNormalization())\r\n",
    "# model.add(LeakyReLU(alpha=0.1))\r\n",
    "# model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "# for i in range(0, 15):\r\n",
    "#     model.add(Conv2D(16, (3, 3), padding='same'))\r\n",
    "#     model.add(BatchNormalization())\r\n",
    "#     model.add(LeakyReLU(alpha=0.1))\r\n",
    "\r\n",
    "# model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "# model.add(BatchNormalization())\r\n",
    "# model.add(LeakyReLU(alpha=0.1))\r\n",
    "# model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "# # model.add(Dropout(0.2))\r\n",
    "# # model.add(Dense(32, activation = 'relu'))\r\n",
    "# # model.add(Dropout(0.4))\r\n",
    "\r\n",
    "# model.add(Conv2D(5, (3, 3), padding='same'))\r\n",
    "# model.add(BatchNormalization())\r\n",
    "# model.add(Softmax())\r\n",
    "\r\n",
    "# # model.add(Conv2D(18, (3, 3), padding='same'))\r\n",
    "# # model.add(Reshape(16, 16, 3, 5))\r\n",
    "# model.add(Reshape((16, 16, 1, 5)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(optimizer = Adam(lr=0.001),\r\n",
    "              loss=custom_loss,\r\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history =model.fit(x = train_datagen , \r\n",
    "                   validation_data = validation_datagen,\r\n",
    "                   steps_per_epoch = num_train_samples,\r\n",
    "                   validation_steps = num_valid_samples,\r\n",
    "                   epochs=5,\r\n",
    "                   verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save(\"trained_SL.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Accuracy and Loss for the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#-----------------------------------------------------------\r\n",
    "# Retrieve a list of list results on training and test data\r\n",
    "# sets for each training epoch\r\n",
    "#-----------------------------------------------------------\r\n",
    "acc       = history.history[     'accuracy' ]\r\n",
    "val_acc   = history.history[ 'val_accuracy' ]\r\n",
    "loss     = history.history[    'loss' ]\r\n",
    "val_loss = history.history['val_loss' ]\r\n",
    "\r\n",
    "epochs   = range(len(acc)) # Get number of epochs\r\n",
    "\r\n",
    "#------------------------------------------------\r\n",
    "# Plot training and validation accuracy per epoch\r\n",
    "#------------------------------------------------\r\n",
    "plt.plot  ( epochs,     acc ,   label = 'training')\r\n",
    "plt.plot  ( epochs, val_acc , label = 'validation')\r\n",
    "plt.legend(loc = 'upper left')\r\n",
    "plt.title ('Training and validation accuracy')\r\n",
    "plt.savefig(\"accurcy-plot.png\")\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "#------------------------------------------------\r\n",
    "# Plot training and validation loss per epoch\r\n",
    "#------------------------------------------------\r\n",
    "plt.plot  ( epochs,     loss ,    label = 'training')\r\n",
    "plt.plot  ( epochs, val_loss , label = 'validation' )\r\n",
    "plt.legend(loc = 'upper left')\r\n",
    "plt.title ('Training and validation loss'   )\r\n",
    "plt.savefig(\"loss-plot.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "REAL_IMG_PATHS = Path(\"datasets/real_shafts/10imgs\")\r\n",
    "real_img_paths = list(TRAIN_DATASET_PATH.glob(\"**/*.bmp\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.keras.models.load_model(\"trained_SL.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def decode_annot(output):\r\n",
    "\r\n",
    "    grid_w = 8\r\n",
    "    grid_h = 8\r\n",
    "    x_0= []\r\n",
    "    y_0= []\r\n",
    "    gamma= []\r\n",
    "    conf= []\r\n",
    "    #classes= []\r\n",
    "    for i in range(16):\r\n",
    "        for j in range(16):\r\n",
    "    \r\n",
    "            if output[i,j,4] > 0.8:\r\n",
    "                X = output[i,j,0]*grid_w + grid_w*i\r\n",
    "                x_0.append(X)\r\n",
    "\r\n",
    "                Y = output[i,j,1]*grid_h + grid_h*j\r\n",
    "                y_0.append(Y)\r\n",
    "\r\n",
    "                angle = 0.5*math.asin((2*output[i,j,3] - 1))              \r\n",
    "                gamma.append(angle)\r\n",
    "                conf.append(output[i,j,4])\r\n",
    "                #classes.append(output[i,j,5])\r\n",
    "    \r\n",
    "    return x_0, y_0, gamma, conf #, classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(str(real_img_paths[0]), 0)\r\n",
    "img_ = cv2.resize(img, (128, 128))\r\n",
    "img_ = img_ / 255\r\n",
    "img_ = np.expand_dims(img_, axis=-1)\r\n",
    "img_ = np.expand_dims(img_, axis=0)\r\n",
    "out = model.predict(img_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reshaped = out.reshape((16, 16, 5))\r\n",
    "print(reshaped)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.max(reshaped[:,:,4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x , y, gamma, conf = decode_annot(reshaped)\r\n",
    "\r\n",
    "#print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "draw_annot(img, x, y, gamma, conf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PRACTICE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train = np.zeros([128, 128, 1])\r\n",
    "y_train = np.zeros([16, 16, 1, 5])\r\n",
    "\r\n",
    "                \r\n",
    "img = cv2.imread(str(train_img_paths[30]))\r\n",
    "img = cv2.resize(img,(128,128))\r\n",
    "img = img/255\r\n",
    "\r\n",
    "annot = np.loadtxt(train_ann_paths[30])\r\n",
    "#finding which grid the object belongs to      \r\n",
    "grid_x = annot[:,1]//grid_w\r\n",
    "grid_y = annot[:,2]//grid_h\r\n",
    "\r\n",
    "row = 0\r\n",
    "                \r\n",
    "for cell_x, cell_y in zip(grid_x, grid_y):\r\n",
    "    y_train[int(cell_y), int(cell_x), 0, 0] = (annot[row, 1] - grid_w * int(cell_x)) / grid_w # x_0\r\n",
    "    y_train[int(cell_y), int(cell_x), 0, 1] = (annot[row, 2] - grid_h * int(cell_y)) / grid_h # y_0\r\n",
    "    y_train[int(cell_y), int(cell_x), 0, 2] = (math.sin(annot[row, 3]))**2 # I_xx\r\n",
    "    y_train[int(cell_y), int(cell_x), 0, 3] = (math.sin(2*annot[row, 4])+1)*0.5 # I_xy\r\n",
    "    y_train[int(cell_y), int(cell_x), 0, 4] = 1 # conf\r\n",
    "    #y_train[i,int(cell_y), int(cell_x), 0, 5] = annot[row, 0] # class\r\n",
    "    row = row+1\r\n",
    "\r\n",
    "reshaped = y_train.reshape((16, 16, 5)) \r\n",
    "\r\n",
    "np.max(reshaped[:,:,4])\r\n",
    "\r\n",
    "# x , y, gamma, conf = decode_annot(reshaped)\r\n",
    "# draw_annot(img, x, y, gamma, conf)\r\n",
    "\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Old Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "    model = tf.keras.Sequential()\r\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(128, 128, 1)))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(LeakyReLU(alpha=0.1))\r\n",
    "\r\n",
    "    for i in range(0, 20):\r\n",
    "        model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "        model.add(BatchNormalization())\r\n",
    "        model.add(LeakyReLU(alpha=0.1))\r\n",
    "    \r\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(LeakyReLU(alpha=0.1))\r\n",
    "    model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "    for i in range(0, 15):\r\n",
    "        model.add(Conv2D(16, (3, 3), padding='same'))\r\n",
    "        model.add(BatchNormalization())\r\n",
    "        model.add(LeakyReLU(alpha=0.1))\r\n",
    "    \r\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(LeakyReLU(alpha=0.1))\r\n",
    "    model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "    for i in range(0, 15):\r\n",
    "        model.add(Conv2D(16, (3, 3), padding='same'))\r\n",
    "        model.add(BatchNormalization())\r\n",
    "        model.add(LeakyReLU(alpha=0.1))\r\n",
    "\r\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(LeakyReLU(alpha=0.1))\r\n",
    "    model.add(AveragePooling2D(2, 2))\r\n",
    "\r\n",
    "    model.add(Dropout(0.2))\r\n",
    "    model.add(Dense(32, activation = 'relu'))\r\n",
    "    model.add(Dropout(0.4))\r\n",
    "\r\n",
    "    model.add(Conv2D(6, (3, 3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(LeakyReLU(alpha=0.1))\r\n",
    "\r\n",
    "    #model.add(Conv2D(18, (3, 3), padding='same'))\r\n",
    "    #model.add(Reshape(16,16,3,6))\r\n",
    "    model.add(Reshape(16,16,1,6))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoding Custom Loss\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "grid_w = 8\r\n",
    "grid_h = 8\r\n",
    "y_train = np.zeros([10, 16, 16, 1, 5])\r\n",
    "i=0\r\n",
    "for ann_name in train_ann_paths[0:10]:\r\n",
    "\r\n",
    "    annot = np.loadtxt(ann_name)\r\n",
    "    #finding which grid the object belongs to      \r\n",
    "    grid_x = annot[:,1]//grid_w\r\n",
    "    grid_y = annot[:,2]//grid_h\r\n",
    "\r\n",
    "    row = 0            \r\n",
    "    for cell_x, cell_y in zip(grid_x, grid_y):\r\n",
    "        y_train[i,int(cell_y), int(cell_x), 0, 0] = (annot[row, 1] - grid_w * int(cell_x)) / grid_w # x_0\r\n",
    "        y_train[i,int(cell_y), int(cell_x), 0, 1] = (annot[row, 2] - grid_h * int(cell_y)) / grid_h # y_0\r\n",
    "        y_train[i,int(cell_y), int(cell_x), 0, 2] = (math.sin(annot[row, 3]))**2 # I_xx\r\n",
    "        y_train[i,int(cell_y), int(cell_x), 0, 3] = (math.sin(2*annot[row, 4])+1)*0.5 # I_xy\r\n",
    "        y_train[i,int(cell_y), int(cell_x), 0, 4] = 1 # conf\r\n",
    "        #y_train[i,int(cell_y), int(cell_x), 0, 5] = annot[row, 0] # class\r\n",
    "        row = row+1 \r\n",
    "    i = i+1 \r\n",
    "np.max(y_train[:,:,:,:,0])\r\n",
    "# count=np.count_nonzero(y_train[:,:,:,:,4])\r\n",
    "# print(count)\r\n",
    "# print(y_train[:,:,:,:,4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DIRECTION_SCALE = 5.0\r\n",
    "COORD_SCALE = 1.0\r\n",
    "OBJECT_SCALE = 10.0\r\n",
    "CLASS_SCALE = 1.0\r\n",
    "NO_OBJECT_SCALE = 5\r\n",
    "    \r\n",
    "mask_shape = tf.shape(y_train)[:4]\r\n",
    "\r\n",
    "coord_mask = tf.zeros(mask_shape)\r\n",
    "direction_mask = tf.zeros(mask_shape)\r\n",
    "conf_mask  = tf.zeros(mask_shape)\r\n",
    "class_mask = tf.zeros(mask_shape)\r\n",
    "\r\n",
    "true_xy = y_train[..., 0:2]    \r\n",
    "true_exy = y_train[..., 2:4]\r\n",
    "true_conf = y_train[..., 4]\r\n",
    "true_class = y_train[..., 5:]\r\n",
    "\r\n",
    "coord_mask = tf.expand_dims(y_train[..., 4], axis=-1) * COORD_SCALE\r\n",
    "direction_mask = tf.expand_dims(y_train[..., 4], axis=-1) * DIRECTION_SCALE\r\n",
    "conf_mask = conf_mask + tf.cast((1 - y_true[..., 4])) * NO_OBJECT_SCALE\r\n",
    "# conf_mask = conf_mask + y_train[..., 4] * OBJECT_SCALE\r\n",
    "class_mask = tf.expand_dims(y_train[..., 4], axis=-1) * CLASS_SCALE\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# nb_coord_kpp = tf.reduce_sum(tf.cast(coord_mask > 0.0, dtype=tf.float32))\r\n",
    "# nb_conf_kpp = tf.reduce_sum(tf.cast(conf_mask > 0.0, dtype=tf.float32))\r\n",
    "# nb_class_kpp = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count=np.count_nonzero(coord_mask)\r\n",
    "print(count)\r\n",
    "\r\n",
    "np.max(coord_mask)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mask = tf.ones(mask_shape)\r\n",
    "# mask=mask *3\r\n",
    "\r\n",
    "# co_mask = tf.expand_dims(mask, axis=-1)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec0e007005ff76f92e7f79ed5f98b599fbe035c2eb365d9361a140832d17fa63"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('tf-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}